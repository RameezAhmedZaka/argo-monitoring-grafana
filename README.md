# DevOps Monitoring & Deployment Infrastructure

This project sets up a complete cloud-native monitoring and deployment environment using **Prometheus**, **Grafana**, **ArgoCD**, **Kubernetes**, and automated CI/CD using **GitHub Actions**.

It is built to provide full observability into Kubernetes workloads, especially **ArgoCD Application health, sync status, and controller performance**, using custom Grafana dashboards.

---

## ğŸš€ Features

### ğŸ”¹ **1. Kubernetes Cluster Deployment (Terraform)**

* Infrastructure provisioned using Terraform.
* Master and Worker nodes deployed in private subnets.
* Bastion/SSM-based access to private nodes.
* Automated kubeadm initialization using Terraform + remote-exec.

### ğŸ”¹ **2. Prometheus Monitoring Stack (Helm Chart)**

* Installed using the official **prometheus-community/kube-prometheus-stack** chart.
* Includes:

  * Prometheus Server
  * Alertmanager
  * Node Exporter
  * Kube State Metrics
  * ServiceMonitors & PodMonitors

### ğŸ”¹ **3. Full ArgoCD Monitoring Integration**

* Added `ServiceMonitor` for all ArgoCD components:

  * application-controller
  * repo-server
  * server
  * redis
  * notifications
  * applicationset controller
* Prometheus now automatically scrapes ArgoCD metrics.

### ğŸ”¹ **4. Grafana Dashboards for ArgoCD**

* Custom dashboards for:

  * ArgoCD sync status
  * OutOfSync application count
  * Deployment frequencies
  * ArgoCD controller performance
* Dashboards are generated via JSON in a dedicated directory:

```
â”œâ”€â”€ grafana-argocd-dashboard-scripts
â”‚Â Â  â”œâ”€â”€ argocd-dashboard-alternative-2.json
â”‚Â Â  â”œâ”€â”€ argocd-dashboard-alternative.json
â”‚Â Â  â””â”€â”€ argocd-dashboard.json
```

### ğŸ”¹ **5. CI/CD via GitHub Actions**

* Fully automated pipeline:

  * On push â†’ build â†’ test â†’ deploy application.
  * Deploys container images to EC2/K8s using GitHub Secrets.
  * Trigger ArgoCD sync automatically.
  * Uses environment-specific workflows (dev/prod).

---

## ğŸ“Š Monitoring Metrics Included

### **ArgoCD Metrics Captured**

* `argocd_app_sync_total`
* `argocd_app_health_status`
* `argocd_app_sync_status`
* `argocd_app_unhealthy`
* `argocd_app_info`
* `etc`


### **Node & Cluster Metrics**

* CPU / RAM usage
* Pod/Node availability
* API server health
* Kubelet performance

---

## ğŸ§© Folder Structure

```
â”œâ”€â”€ grafana-argocd-dashboard-scripts
â”‚Â Â  â”œâ”€â”€ argocd-dashboard-alternative-2.json
â”‚Â Â  â”œâ”€â”€ argocd-dashboard-alternative.json
â”‚Â Â  â””â”€â”€ argocd-dashboard.json
â”œâ”€â”€ k8s-setup
â”‚Â Â  â”œâ”€â”€ config
â”‚Â Â  â”‚Â Â  â””â”€â”€ dev.tfvars
â”‚Â Â  â”œâ”€â”€ data.tf
â”‚Â Â  â”œâ”€â”€ main.tf
â”‚Â Â  â”œâ”€â”€ modules
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ argocd
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ argocd_app.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ argocd_projects_apps.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ argocd_repo.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ github_secret.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ main.tf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ variable.tf
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ iam
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ main.tf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ output.tf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ variable.tf
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ manager
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ main.tf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ output.tf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ user_data_ssm.sh
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ variable.tf
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ monitoring
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ main.tf
â”‚Â Â  â”‚Â Â  â””â”€â”€ nodes
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ main.tf
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ output.tf
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ user_data_master.sh
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ user_data_worker.sh
â”‚Â Â  â”‚Â Â      â””â”€â”€ variables.tf
â”‚Â Â  â”œâ”€â”€ output.tf
â”‚Â Â  â”œâ”€â”€ provider.tf
â”‚Â Â  â””â”€â”€ variables.tf
â”œâ”€â”€ network
â”‚Â Â  â”œâ”€â”€ config
â”‚Â Â  â”‚Â Â  â””â”€â”€ dev.tfvars
â”‚Â Â  â”œâ”€â”€ main.tf
â”‚Â Â  â”œâ”€â”€ modules
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ bastion
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ main.tf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ output.tf
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ user_data.sh
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ variables.tf
â”‚Â Â  â”‚Â Â  â””â”€â”€ vpc
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ main.tf
â”‚Â Â  â”‚Â Â      â”œâ”€â”€ output.tf
â”‚Â Â  â”‚Â Â      â””â”€â”€ variables.tf
â”‚Â Â  â”œâ”€â”€ output.tf
â”‚Â Â  â”œâ”€â”€ provider.tf
â”‚Â Â  â””â”€â”€ variable.tf
â””â”€â”€ README.md

```

---

## ğŸ› ï¸ How to Deploy

First setup the `network` by going inside the network and running 
```
terraform init
terraform apply -var-file=config/dev.tfvars
```
Then go inside the bashion and clone the code of `k8s-setup` and than than run:

```
terraform init
terraform apply -var-file=config/dev.tfvars
```
### **Prometheus Dashboards**
Run this for accessing the prometheus dashboard.
```
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
```
### ** Import Grafana Dashboards**
For accessing the grafana UI.
```
kubectl port-forward svc/prometheus-grafana -n monitoring 3000:80
```
1. Run this to access the grafana dashboard UI.
2. The username will be `admin` and the the password will be `admin123`.
3. After logging in click in `+` icon and than paste the json file there to import the dashboard. The json files are present in the dir `grafana-argocd-dashboard-scripts`.

## ğŸ¯ Purpose of This Project

This setup is designed for:

* Complete observability of ArgoCD deployments.
* Understanding sync failures, performance, and app status.
* Monitoring Kubernetes cluster health.
* Automated CI/CD pipelines using GitHub Actions.
* Production-grade infrastructure with Terraform + Helm.

---
